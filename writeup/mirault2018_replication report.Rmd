---
title: "Replication of Online Experiment by Mirault, Snell, and Grainger (2018, Psychological Science)"
author: "Alvin Tan (tanawm@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

<!--Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results.-->

## Introduction

<!--[No abstract is needed.]  Each replication project will have a straightforward, no frills report of the study and results.  These reports will be publicly available as supplementary material for the aggregate report(s) of the project as a whole.  Also, to maximize project integrity, the intro and methods will be written and critiqued in advance of data collection.  Introductions can be just 1-2 paragraphs clarifying the main idea of the original study, the target finding for replication, and any other essential information.  It will NOT have a literature review -- that is in the original publication. You can write both the introduction and the methods in past tense.-->

In their paper, [Mirault et al. (2018)](https://github.com/psych251/mirault2018/blob/main/original_paper/mirault2018.pdf) demonstrate a novel transposed word effect in speeded sentence grammaticality judgments. They constructed base sentences that were either grammatical or ungrammatical, and then derived test sentences from them by transposing two words, finding that ungrammaticality judgments for transposed word sentences required longer reaction times and had higher error rates when the base sentences were grammatical. The authors suggested that these results demonstrate some uncertainty in word order encoding as well as parallel processing of words. 

This transposed word effect has important implications in psycholinguistics, particularly regarding models of sentence processing and grammar. Furthermore, since the effect is a relatively novel phenomenon, it should be verified through replications and reproductions in order to demonstrate its robustness. In particular, the original study was conducted in French, which has agreement (in person, number, and gender) among verbs, articles, adjectives, and nouns. This contrasts with English, which has much more limited agreement (only between subjects and verbs). Additionally, French has certain word orders which are much less common or not possible in English (e.g. adjectives after nouns, direct object before verb). Replicating the effect in English would thus demonstrate that the effect is not solely due to the particular agreement or word order characteristics of French, but can generalise across languages.

The materials needed to replicate this study include the test sentences (which serve as stimuli for the speeded grammaticality judgment task), as well as the specific instructions given to participants. The former are available on the paper's [OSF site](https://osf.io/mvz3r/); however, the latter will have to be obtained by communicating with the authors. The original experiment was conducted online using Java, and a similar implementation (using JavaScript) on a crowdsourcing platform will be adopted for the replication study. 

Since the materials, procedures, and analyses have been described in Mirault et al.'s paper to quite a good degree of detail, a reimplementation of the experimental and analytical designs is likely to be relatively straightforward as long as the specific instructions can be obtained from the authors. The most important challenge is the development of English test stimuli that are sufficiently close in construction to the French test stimuli in order to avoid the effects of improper stimuli. 

The repository for this project is hosted on [GitHub](https://github.com/psych251/mirault2018).

## Methods

### Power Analysis

<!--Original effect size, power analysis for samples to achieve 80%, 90%, 95% power to detect that effect size.  Considerations of feasibility for selecting planned sample size.-->

I reproduced the data processing and analysis methods using the original data so that the mixed-effects model could be directly used to estimate power by simulation.

```{r "library config", cache = FALSE, include = FALSE}
require(knitr)
orig_dir <- "../original_paper/original_data/"
opts_knit$set(root.dir = orig_dir)

#### Load relevant libraries
require(lme4)
require(tidyverse)
require(magrittr)
require(ggplot2)
require(cowplot)
require(simr)
```

```{r "original data processing"}
### Power analysis
setwd(orig_dir)

#### Import data
orig_files <- grep(".txt$", list.files(), value = TRUE)

orig_data_df <- data.frame()
orig_data_list <- list()

for (file_no in seq_along(orig_files)) {
  new_orig_data <- scan(orig_files[file_no], sep = "@", what = "character", quiet = TRUE) 
  new_orig_data_df <- as.data.frame(do.call(rbind, strsplit(new_orig_data, split = ";")))
  names(new_orig_data_df) <- c("trial", "item_no", "start_time", "end_time", "response", "condition", "group")
  new_orig_data_df$participant <- file_no
  orig_data_list[[file_no]] <- new_orig_data_df[-161,]
}
orig_data_df <- bind_rows(orig_data_list) 

#### Pre-process data
substring(orig_data_df$start_time, 9, 9) <- "." # handle time format
substring(orig_data_df$end_time, 9, 9) <- "."

orig_data_df <- orig_data_df %>% mutate(rt = 1000 * difftime(paste("2026-01-01", .$end_time), 
                                             paste("2026-01-01", .$start_time)))
attributes(orig_data_df$rt)$units = "milliseconds"
orig_data_df$rt <- round(orig_data_df$rt, 0)

orig_data_df <- orig_data_df %>% mutate(correct = ((.$condition > 0 & .$response == 0) | 
                                                      (.$condition == 0 & .$response == 1)))

#### Convert data into correct format
orig_data_df$rt <- as.numeric(orig_data_df$rt)
orig_data_df$correct <- as.logical(orig_data_df$correct)
orig_data_df$condition <- as_factor(recode(orig_data_df$condition, 
                                           "0" = "gram", "1" = "transword", "2" = "control"))
orig_data_df$item_no <- as_factor(orig_data_df$item_no)
orig_data_df$participant <- as_factor(orig_data_df$participant)

#### Data exclusion
summary_orig_tbl <- orig_data_df %>% 
  group_by(participant) %>%
  summarise(avg_rt = mean(rt, na.rm = TRUE), accuracy = mean(correct, na.rm = TRUE), 
            .groups = 'drop')

summary_orig_tbl <- summary_orig_tbl %>%
  mutate(acc_exclude = (accuracy < 0.5)) %>%
  mutate(rt_z = scale(avg_rt)) %>%
  mutate(rt_exclude = (abs(rt_z) > 2.5))

summary_orig_tbl_exclude <- summary_orig_tbl %>%
  filter(acc_exclude == TRUE | rt_exclude == TRUE)

orig_data_df %<>% filter(rt != 0)

orig_data_df_filtered <- orig_data_df %>%
  filter(condition != "gram")

orig_data_df_excluded <- orig_data_df_filtered %>%
  ##  note: original authors did not exclude any ppts, but according to their exclusion criteria they should 
  ##  have excluded one ppt (mean RT > 2.5 SDs from mean)
  filter(!(participant %in% summary_orig_tbl_exclude$participant)) 
```

After pre-processing the data, I noticed that the authors should have excluded one participant based on their exclusion criterion (mean RT > 2.5 standard deviations from mean); however, it was unclear whether this participant was or was not excluded. I thus attempted to reproduce the original findings and run a power analysis on both the excluded and unexcluded data.

```{r "power analysis - no exclusion", warning=F}
keyEffects <- function(data_df) {
  #### LME model preparation
  data_df$condition <- relevel(data_df$condition, ref = "control")
  
  orig_data_df_correct <- data_df %>%
    filter(correct) %>%
    filter(condition != "gram")
  
  rt_orig_model <- lmer((-1000 / rt) ~ condition + (1|item_no) + (1|participant),
                        data = orig_data_df_correct, na.action = na.exclude,
                        control = lmerControl(check.conv.singular = .makeCC(action = "ignore", tol = 1e-4)))
  
  print(summary(rt_orig_model))
  
  #### Accuracy GLME (included for completeness)
  accuracy_orig_model <- glmer((1 - correct) ~ condition + (1|item_no) + (1|participant),
                               data = orig_data_df_filtered, family = 'binomial',
                               control = glmerControl(check.conv.singular = 
                                                       .makeCC(action = "ignore", tol = 1e-4)))
  
  print(summary(accuracy_orig_model))
  
  return(list(rt_orig_model, accuracy_orig_model))
}

models_included <- keyEffects(orig_data_df_filtered)
models_excluded <- keyEffects(orig_data_df_excluded)

powerAnalysis <- function(rt_model) {
  #### Post-hoc power analysis
  power <- powerSim(rt_model, nsim = 200, progress = FALSE)
  print(power)
  
  #### Power curve plotting
  pwr_crv <- powerCurve(rt_model, along = "participant", nsim = 50, progress = FALSE)
  pwr_crv_summary <- summary(pwr_crv)
  pwr_levels = c(0.8, 0.9, 0.95) * summary(power)$mean
  
  pwr_crv_plot <- ggplot(pwr_crv_summary, aes(x = nlevels, y = mean * 100)) +
    geom_errorbar(aes(ymin = lower * 100, ymax = upper * 100), width = 1.2, colour = "#0097a7") +
    geom_line(colour = "#0097a7") +
    coord_cartesian(xlim = c(0, 100), ylim = c(0, 100)) +
    geom_hline(yintercept = pwr_levels * 100, linetype = "dashed", colour = "#555555") +
    annotate("text", x = 5, y = pwr_levels[1:2] * 100 - 2.5, label = c("80% original", "90% original"), 
             colour = "#555555") +
    annotate("text", x = 5, y = pwr_levels[3] * 100 + 2.7, label = "95% original", colour = "#555555") + 
    labs(x = "Number of participants", y = "Estimated power by simulation (%)")
    #+ geom_vline(xintercept = c(59, 67, 76)) # approx values for 80%, 90%, and 95% original power 
  
  plot(pwr_crv_plot)
  
  return(list(power, pwr_crv, pwr_crv_plot))
}

power_analysis_included <- powerAnalysis(models_included[[1]])
power_analysis_excluded <- powerAnalysis(models_excluded[[1]])

# use these to display relevant info if you do not wish to rerun the simulations
# print(power_analysis_included[[1]])
# print(power_analysis_excluded[[1]])
# plot(power_analysis_included[[3]])
# plot(power_analysis_excluded[[3]])
```

Based on the power analysis, the power of the original study is 100%. As such, 23 participants are needed to achieve the same power as the original study. 

### Planned Sample

<!--Planned sample size and/or termination rule, sampling frame, known demographics if any, preselection rules if any.-->

The planned sample size is 25, which can achieve 100% of the power of the original study while allowing for some buffer (for exclusions). 

### Materials

<!--All materials - can quote directly from original article - just put the text in quotations and note that this was followed precisely.  Or, quote directly and just point out exceptions to what was described in the original article.-->

As the present replication involves a different language from the original study, new stimuli were created in English according to the specifications of the original study. Pairs of five-word grammatical base sentences were constructed, largely using translated lexical items from the original French, modifying where necessary to avoid semantic oddity, to minimize repetitions of lexical items, and to produce sentences that were amenable to the subsequent manipulations. The last words of each pair were then swapped to produce corresponding pairs of ungrammatical base sentences. Finally, the third and fourth words of each base sentence were transposed to form the test sequences, such that the transposed words were of different grammatical categories. Following the original authors, I will refer to the two conditions as the transposed-word condition (derived from a grammatical base sentence) and the control condition (derived from an ungrammatical base sentence). These are illustrated in Table 1.

<center>

*Table 1.* Examples of base sentences and test sequences

</center>

```{r "table1", echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
# table solution taken from https://stackoverflow.com/questions/19997242/simple-manual-rmarkdown-tables-that-look-good-in-html-pdf-and-docx

examples <- "
| Sequence           | Example                          |
|--------------------|----------------------------------|
| Base               |                                  |
| -  Grammatical     | You should really leave now.     |
|                    | Her handsome neighbor is moving. |
| -  Ungrammatical   | You should really leave moving.  |
|                    | Her handsome neighbor is now.    |
| Test               |                                  |
| -  Transposed-word | You should leave really now.     |
|                    | Her handsome is neighbor moving. |
| -  Control         | You should leave really moving.  |
|                    | Her handsome is neighbor now.    |
"
cat(examples) 
```

The remainder of the stimulus construction followed the original study: 160 ungrammatical test sequences were constructed from 80 grammatical and 80 ungrammatical base sentences. These were distributed into two lists, such that participants only saw half of each type of test sequence, and did not experience "repetition of sequences containing the same words". Additionally, "each participant also saw 80 grammatically correct sentences that were not related in any way to the base sequences used to generate the ungrammatical test sequences." 

The full set of English stimuli can be found [here](https://github.com/psych251/mirault2018/blob/main/experiment/stimuli.csv). In this file, items 1--40 have transposed-word sequences in List 1 and control sequences in List 2, items 41--80 have control sequences in List 1 and transposed-word sequences in List 2, and items 81--160 are grammatically correct sentences identical in both lists.

### Procedure	

<!--Can quote directly from original article - just put the text in quotations and note that this was followed precisely.  Or, quote directly and just point out exceptions to what was described in the original article.-->

The procedure from the original paper was followed closely: "Participants were instructed to decide as rapidly and as accurately as possible whether the sequence of words was grammatically correct. On each trial, a fixation cross was displayed on the center of the screen during a random time ranging between 500 and 700 ms, followed by the stimulus (a five-word sequence) centered on the screen. The distance between the central fixation cross and the first letter of the sequence varied between 8° and 18° of visual angle as a function of the length of the five-word sequence. The word sequence remained on screen until response. After this, a feedback dot was presented for 700 ms, in green if the response was correct or in red if the response was incorrect."

Additional detail regarding online presentation was as follows: "Stimuli were presented online using Java protocol on the personal computer of the participant. Sentences were presented in 30-point mono-spaced font (Droid Sans Mono) in black on a white background. Participants were asked to sit about 60 cm from the monitor, such that 1 cm equaled approximately 1° of visual angle. Participants responded using their index fingers with two arrows on the computer keyboard: right for grammatical decisions and left for ungrammatical decisions."

A few minor deviations from the abovementioned procedure were adopted. Firstly, the experiment was coded using JavaScript (relying on the jsPsych library) instead of Java. Secondly, two practice questions were given to ensure that participants were familiar with the paradigm before commencing. Thirdly, the experiment was divided into four blocks comprising 40 pseudorandomised questions each to alleviate the load on sustained attention. Finally, the keypresses were changed to 'F' and 'J' instead of the arrow keys to ensure that participants were using both index fingers, rather than two fingers on their right hand. These are unlikely to result in a substantial difference in results as they do not affect the main experimental manipulations.

The experiment can be found [here](https://web.stanford.edu/~tanawm/mirault2018/experiment.html), and the code for the experiment can be found [here](https://github.com/psych251/mirault2018/blob/main/experiment/experiment.html).

### Analysis Plan

<!--Can also quote directly, though it is less often spelled out effectively for an analysis strategy section.  The key is to report an analysis strategy that is as close to the original - data cleaning rules, data exclusion rules, covariates, etc. - as possible.-->

As with the original paper, "response times (RT; the time between onset of stimulus presentation and participant’s response) for correct responses and response accuracy" were analyzed. Similarly, prior to analysis, RTs were also inverse-transformed (-1000/RT) to normalize the distribution. 

#### Exclusion criteria

The exclusion criteria used in the original paper were:

1. Low overall accuracy (no specific cutoff), and
2. RTs beyond 2.5 standard deviations from the grand mean.

These were adopted for the present replication, with an accuracy cutoff specified at 50% (i.e. at chance), such that participants who performed worse than chance were excluded. A third exclusion criterion of incomplete responses was also added to account for the potential technical difficulties of working on a crowdsourcing platform.

<!--**Clarify key analysis of interest here**  You can also pre-specify additional analyses you plan to do.-->

#### Key analyses of interest

The key analyses of the original paper were:

1. Linear mixed-effects (LME) model to analyze RTs, and
2. Generalized (logistic) linear mixed-effects (GLME) model to analyze accuracy.

These effects were considered to be reliable if |*t*| (for LME) or |*z*| (for GLME) were greater than 1.96. Furthermore, the original authors "used the maximal random structure model that converged ..., and this included by-participant and by-item random intercepts in all analyses". These analyses were also adopted for the present replication.

### Differences from Original Study

<!--Explicitly describe known differences in sample, setting, procedure, and analysis plan from original study. The goal, of course, is to minimize those differences, but differences will inevitably occur. Also, note whether such differences are anticipated to make a difference based on claims in the original article or subsequent published research on the conditions for obtaining the effect.-->

In summary, two key methodological differences exist between the original study and the present replication. These are the recruitment of participants on MTurk (instead of volunteers), and the use of novel English stimuli (instead of the original French). The former may influence the results to a small extent due to motivation differences, but it is unlikely to result in a significant change in the result, considering that the study involves a response time task. The latter, however, is much more likely to affect the result. Whether the present replication succeeds or fails would thus depend strongly on whether the transposed-word effect is generalizable to English.

<!--### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.-->

#### Actual Sample
<!--Sample size, demographics, data exclusions based on rules spelled out in analysis plan-->

#### Differences from pre-data collection methods plan
<!--Any differences from what was described as the original plan, or “none”.-->


## Results


### Data preparation

<!--Data preparation following the analysis plan.-->
The data were first prepared by extracting the relevant trials and implementing the exclusion criteria.

```{r "dir config", cache = FALSE, include = FALSE}
data_dir <- "./../../data"
opts_knit$set(root.dir = 'data_dir')
```

```{r "data prep"}
### Data Preparation
setwd(data_dir)

#### Import data
files <- grep(".csv$", list.files(), value = TRUE)

full_data_df <- data.frame()
full_data_list <- list()

for (file_no in seq_along(files)) {
  new_data_df <- read.csv(files[file_no])
  full_data_list[[file_no]] <- new_data_df
}
full_data_df <- bind_rows(full_data_list) 

#### Filter trial data
full_data_df %<>% 
  filter(grepl("<p class='stimulus'>", .$stimulus, perl = TRUE)) %>%
  select(-participant) %>%
  rename(participant = uid)

full_data_df$stimulus %<>%
  sub("<p class='stimulus'>", "", ., perl = TRUE) %>%
  sub("</p>", "", ., perl = TRUE)

#### Convert data into correct format
full_data_df$participant <- as_factor(full_data_df$participant)
full_data_df$rt <- as.numeric(full_data_df$rt)
full_data_df$correct <- as.logical(full_data_df$correct)
full_data_df$condition <- as_factor(full_data_df$condition)

#### Data exclusion
summary_tbl <- full_data_df %>% 
  group_by(participant) %>%
  summarise(avg_rt = mean(rt, na.rm = TRUE), accuracy = mean(correct, na.rm = TRUE), 
            .groups = 'drop')

summary_tbl %<>%
  mutate(acc_exclude = (accuracy < 0.5)) %>%
  mutate(rt_z = scale(avg_rt)) %>%
  mutate(rt_exclude = (abs(rt_z) > 2.5))

summary_tbl_exclude <- summary_tbl %>%
  filter(acc_exclude == TRUE | rt_exclude == TRUE)

full_data_df_filtered <- full_data_df %>%
  filter(!(participant %in% summary_tbl_exclude$participant))
```

### Confirmatory analysis

<!--The analyses as specified in the analysis plan.-->
An LME was then used to analyse the RT data, and a GLME was used to analyse the accuracy data.

```{r "confirm analysis"}
### Confirmatory analysis
models <- keyEffects(full_data_df_filtered)
```

<!--*Side-by-side graph with original graph is ideal here*-->

```{r "graph"}
#### Generate summary tables
se <- function(x) sd(x) / sqrt(length(x))

color_scale <- c("#0097a7", "#e06666", "#93c47d")

make_summary <- function(data_df, is_acc) {
  if (is_acc) {
    summary_df <- data_df %>%
      group_by(condition) %>%
      summarise(mean_err = 100 * (1 - mean(correct, na.rm = TRUE)),
            err_sem = se(100 * (1 - na.omit(correct))), .groups = "drop")
  } else {
    summary_df = data_df %>% 
      group_by(condition) %>%
      summarise(mean_rt = mean(rt, na.rm = TRUE), rt_sem = se(na.omit(rt)), .groups = "drop")
  }
  return(summary_df)
}

orig_rt_summary <- make_summary(orig_data_df, 0)
orig_acc_summary <- make_summary(orig_data_df, 1)

rt_summary <- make_summary(full_data_df_filtered, 0)
acc_summary <- make_summary(full_data_df_filtered, 1)

#### Generate summary plots
plot_summary <- function(summary_df, is_acc) {
  summary_df %<>%
    mutate(condition = fct_relevel(condition, "transword", "control", "gram"))

  mean_var <- ifelse(is_acc, as.name("mean_err"), as.name("mean_rt"))
  sem_var <- ifelse(is_acc, as.name("err_sem"), as.name("rt_sem"))
  y_lab <- ifelse(is_acc, "Error rate (%)", "Response time (ms)")
  
  summary_plot <- ggplot(summary_df, aes(x = condition, y = !!mean_var, fill = condition)) + 
    geom_bar(position = "dodge", stat = "identity", width = .6) +
    labs(x = "Condition", y = y_lab) +
    scale_fill_manual(values = color_scale) + 
    theme(legend.position = "none") +
    scale_x_discrete(labels = c("TW", "Control", "Grammatical")) +
    geom_errorbar(aes(ymin = !!mean_var - 2 * !!sem_var, ymax = !!mean_var + 2 * !!sem_var), 
                  width = .2, position = position_dodge(.9))
}

orig_rt_plot <- plot_summary(orig_rt_summary, 0)
orig_acc_plot <- plot_summary(orig_acc_summary, 1)

rt_plot <- plot_summary(rt_summary, 0)
acc_plot <- plot_summary(acc_summary, 1)

orig_title <- ggdraw() +
  draw_label("Original results", fontface = "bold", x = 0, hjust = 0) +
  theme(plot.margin = margin(0, 0, 0, 7))

repl_title <- ggdraw() +
  draw_label("Replication results", fontface = "bold", x = 0, hjust = 0) +
  theme(plot.margin = margin(0, 0, 0, 7))

plot_grid(orig_title, plot_grid(orig_rt_plot, orig_acc_plot), ncol = 1, rel_heights = c(0.1, 1))
plot_grid(repl_title, plot_grid(rt_plot, acc_plot), ncol = 1, rel_heights = c(0.1, 1))
```

### Exploratory analyses

<!--Any follow-up analyses desired (not required).-->

## Discussion

### Summary of Replication Attempt

<!--Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.--> 

### Commentary

<!--Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.-->
